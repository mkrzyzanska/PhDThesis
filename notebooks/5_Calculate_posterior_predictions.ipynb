{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries\n",
    "library(here) # for paths\n",
    "library(rstan) # to read the model and calculate the predictions\n",
    "\n",
    "### Source the utility functions:\n",
    "\n",
    "source(here(\"R\",\"square.r\"))\n",
    "source(here(\"R\",\"calculatePredictions.r\"))\n",
    "\n",
    "# Inputs\n",
    "path2models<-here(\"outputs\",\"models\")\n",
    "path2env_sd<-here(\"data\",\"Sd_Env_by_county.csv\")\n",
    "path2past_env<-here(\"data\",\"env_past_std.csv\")\n",
    "path2stats<- here(\"data\",\"Mean_and_SD.csv\")\n",
    "\n",
    "\n",
    "# Outputs\n",
    "path2outputs<-here(\"outputs\")\n",
    "path2predictions<-here(\"outputs\",\"predictions\")\n",
    "path2timeslices<-here(\"outputs\",\"chronology_limits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats<-read.csv(path2stats,row.names=1)\n",
    "env_pres<-read.csv(path2env_sd,row.names=1) # Change name for present\n",
    "env<-read.csv(path2past_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format new data to extract from the posterior\n",
    "\n",
    "# Define the size of the sample from the posterior:\n",
    "n=40000\n",
    "n_cnt=1000\n",
    "\n",
    "# Define the order of the variables as in original stan model:\n",
    "var_ordered<-c('BIO10','BIO17','BIO4','BIO9','npp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops<-c(\"wheat\",\"barley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant columns from the data frame:\n",
    "d<-env_pres[ ,paste(var_ordered,\"sd\",sep=\"_\")]\n",
    "colnames(d)<-var_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (crop in crops){\n",
    "    print(crop)\n",
    "    path2model<-paste(path2models,\"/\",crop,\".rds\",sep=\"\")\n",
    "    path2pred<-paste(path2predictions, \"/\",crop, \"_posterior_predictions\",\".csv\",sep=\"\")\n",
    "    path2pred_s<-paste(path2predictions, \"/\",crop, \"_posterior_predictions_summary\",\".csv\",sep=\"\")\n",
    "    #Read data\n",
    "    fit<-readRDS(path2model)\n",
    "    posterior <- rstan::extract(fit) \n",
    "    \n",
    "    ### Calculate predictions\n",
    "    print(\"Calculating posterior predictions...\")\n",
    "    predictions<-calculatePredictions(fit, d, posterior,n,counterfactual=FALSE)\n",
    "    print(\"Saving posterior predictions...\")\n",
    "    \n",
    "    ### Save predictions:\n",
    "    write.csv(predictions, path2pred,col.names=FALSE, row.names=FALSE)\n",
    "    print(\"Calculating summary...\")\n",
    "    \n",
    "    ### Also calculate the summary\n",
    "    means_pred<-apply(predictions,2, mean) # Calculate mean of each column (column==county)\n",
    "    quantiles_pred<-apply(predictions,2, quantile,probs = c(0.05, 0.95),na.rm=TRUE) # Calculate quantiles of each column (column==county)\n",
    "    fpred<-t(rbind(quantiles_pred, means_pred)) # Bind mean and quantiles, and transpose them, so that each county is a row now\n",
    "    exp_pred<-exp(fpred) # Exponentiate the predictions for all counties\n",
    "    colnames(fpred)<-paste(colnames(fpred),\"log\",sep=\"_\")\n",
    "    fpred<-cbind(fpred,exp_pred) # Bind logarithmic and exponentiate predictions\n",
    "    row.names(fpred)<-c(1:nrow(fpred))\n",
    "    print(\"Saving summary...\")\n",
    "   \n",
    "    ### Save predictions:\n",
    "    write.csv(fpred, path2pred_s,col.names=FALSE, row.names=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices<-read.csv(path2timeslices,row.names=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "row.names(slices)<-tolower(row.names(slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices<-t(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslices<-gsub(\"X\",\"\",names(slices[,crop][slices[,crop]>0]))\n",
    "timeslices<-gsub(\"\\\\.\",\" \",timeslices)\n",
    "timeslices<-factor(timeslices, ordered=TRUE)\n",
    "timeslices<-factor(timeslices,levels=timeslices,ordered=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslices <-c(seq(1000,max,by=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslices<-timeslices[timeslices>\"10000 BP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "    path2model<-paste(path2models,\"/\",crop,\".rds\",sep=\"\")\n",
    "    fit<-readRDS(path2model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions<-calculatePredictions(fit, data, posterior,n,counterfactual=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f<-read.csv(here(\"outputs\",\"predictions\",\"barley_predictions.csv\"),row.names=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in timeslices){\n",
    "        print(i)\n",
    "        data<-env[,grep(paste(\"_\",i,\"_\",sep=\"\"),colnames(env))] # Get only the data for relevent time slice\n",
    "        predictions<-calculatePredictions(fit, data, posterior,n,counterfactual=FALSE) # Calculate predictions for the time slice\n",
    "        write.csv(predictions, paste(path2predictions,\"/\",crop,\"_predictions_\",i,\".csv\",sep=\"\"),col.names=FALSE, row.names=FALSE) # Save past predictions\n",
    "       \n",
    "        ### Also calculate the summary\n",
    "        means_pred<-apply(predictions,2, mean) # Calculate mean of each column (column==county)\n",
    "        quantiles_pred<-apply(predictions,2, quantile,probs = c(0.05, 0.95),na.rm=TRUE) # Calculate quantiles of each column (column==county)\n",
    "        fpred<-t(rbind(quantiles_pred, means_pred)) # Bind mean and quantiles, and transpose them, so that each county is a row now\n",
    "        exp_pred<-exp(fpred) # Exponentiate the predictions for all counties\n",
    "        colnames(exp_pred)<-paste(colnames(fpred),i,sep=\"_\") # Change original names of the columns with predictions, to indicate that they are in lograrithmic form\n",
    "        colnames(fpred)<-paste(colnames(fpred),i,\"log\",sep=\"_\")\n",
    "        fpred<-cbind(fpred,exp_pred) # Bind logarithmic and exponentiate predictions\n",
    "        row.names(fpred)<-c(1:nrow(fpred))\n",
    "        pred<-cbind(pred,fpred)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Past distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (crop in crops){\n",
    "    ### Calculate the predictions for the past:   \n",
    "    timeslices<-gsub(\"X\",\"\",names(slices[,crop][slices[,crop]>0]))\n",
    "    timeslices<-gsub(\"\\\\.\",\" \",timeslices)\n",
    "    timeslices<-factor(timeslices, ordered=TRUE)\n",
    "    timeslices<-factor(timeslices,levels=timeslices,ordered=TRUE)\n",
    "    max<-as.numeric(gsub(\" BP\",\"\",as.character(max(unique(timeslices)))))\n",
    "    timeslices <-c(seq(1000,max,by=1000))\n",
    "    if(crop==\"buckwheat\"){timeslices=c(timeslices,15000)}\n",
    "    if(crop==\"rice\"){timeslices<-as.numeric(gsub(\" BP\",\"\",as.character(unique(timeslices))))}\n",
    "    pred<-c()\n",
    "    #Read data\n",
    "    path2model<-paste(path2models,\"/\",crop,\".rds\",sep=\"\")\n",
    "    fit<-readRDS(path2model)\n",
    "    posterior <- rstan::extract(fit) \n",
    "    # Loop over all time slices\n",
    "    for (i in timeslices){\n",
    "        print(i)\n",
    "        data<-env[,grep(paste(\"_\",i,sep=\"\"),colnames(env))] # Get only the data for relevent time slice\n",
    "        predictions<-calculatePredictions(fit, data, posterior,n,counterfactual=FALSE) # Calculate predictions for the time slice\n",
    "        write.csv(predictions, paste(path2predictions,\"/\",crop,\"_predictions_\",i,\".csv\",sep=\"\"),col.names=FALSE, row.names=FALSE) # Save past predictions\n",
    "       \n",
    "        ### Also calculate the summary\n",
    "        means_pred<-apply(predictions,2, mean) # Calculate mean of each column (column==county)\n",
    "        quantiles_pred<-apply(predictions,2, quantile,probs = c(0.05, 0.95),na.rm=TRUE) # Calculate quantiles of each column (column==county)\n",
    "        fpred<-t(rbind(quantiles_pred, means_pred)) # Bind mean and quantiles, and transpose them, so that each county is a row now\n",
    "        exp_pred<-exp(fpred) # Exponentiate the predictions for all counties\n",
    "        colnames(exp_pred)<-paste(colnames(fpred),i,sep=\"_\") # Change original names of the columns with predictions, to indicate that they are in lograrithmic form\n",
    "        colnames(fpred)<-paste(colnames(fpred),i,\"log\",sep=\"_\")\n",
    "        fpred<-cbind(fpred,exp_pred) # Bind logarithmic and exponentiate predictions\n",
    "        row.names(fpred)<-c(1:nrow(fpred))\n",
    "        pred<-cbind(pred,fpred)\n",
    "}\n",
    "    # Get summary predictions\n",
    "     write.csv(pred, paste(path2predictions,\"/\",crop,\"_predictions\",\".csv\",sep=\"\"))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " write.csv(pred, paste(path2predictions,\"/\",crop,\"_predictions\",\".csv\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate counterfactual predictions\n",
    "# Get new data\n",
    "means<-colMeans(d) # Get mean valuse of all environmental variables\n",
    "means<-as.data.frame(rbind(means)) # Bind the mean values\n",
    "means<-means[rep(seq_len(nrow(means)), each = n_cnt), ] # Repeat each mean value n_cnt time\n",
    "range<-apply(d,2,range) # Get the range of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information about the range to the existing stats summary\n",
    "stats<-cbind(stats,t(range))\n",
    "colnames(stats)[3:4]<-c(\"low_range_sd\",\"high_range_sd\")\n",
    "stats<-as.data.frame(stats)\n",
    "stats$low_range<-stats$low_range_sd*stats$sd+stats$mean\n",
    "stats$high_range<-stats$high_range_sd*stats$sd+stats$mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(stats,path2stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all environmental variables\n",
    "for (crop in crops){\n",
    "    print(crop)\n",
    "    #Read data\n",
    "    path2model<-paste(path2models,\"/\",crop,\".rds\",sep=\"\")\n",
    "    fit<-readRDS(path2model)\n",
    "    posterior <- rstan::extract(fit) \n",
    "    for (i in 1:ncol(d)){\n",
    "        print(i)\n",
    "        new_data<-means # use means as new data\n",
    "        new_data[,i]<-seq(from = range[1,i], to = range[2,i],length.out=n_cnt) # substitute new values for one of the environmental variables\n",
    "        values<-new_data[,i] # Get the values for which predictions ar made\n",
    "        predictions<-calculatePredictions(fit, new_data, posterior,n,counterfactual=TRUE) # calculate predictions for new data\n",
    "        # Save counterfactual predictions\n",
    "        write.csv(predictions, paste(path2outputs,\"/\",crop,\"_counterfactual_predictions_\",var_ordered[i],\".csv\",sep=\"\"),col.names=FALSE, row.names=FALSE)\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
